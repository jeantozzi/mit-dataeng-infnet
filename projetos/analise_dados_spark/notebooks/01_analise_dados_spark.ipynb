{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYgKXfFUrser"
      },
      "source": [
        "# Análise de dados com PySpark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O72qDbrQru4D"
      },
      "source": [
        "Neste notebook, vamos recriar com PySpark as análises feitas anteriormente com SQL no Hive.<br>\n",
        "Para tanto, iremos:\n",
        "1. Baixar e extrair os arquivos utilizados.\n",
        "2. Configurar e iniciar o ambiente do PySpark.\n",
        "3. Realizar as análises em PySpark, com as queries SQL servindo de referência comparativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzZn3ym4rwwW"
      },
      "source": [
        "### Baixando e extraindo os dados utilizados anteriormente no projeto de Infraestrutura Hadoop"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para este passo, prossiga com o upload do arquivo `download_and_extract.sh` que se encontra no repositório."
      ],
      "metadata": {
        "id": "5pDNpVPxRTf6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfaXhApwl2Td",
        "outputId": "9de28e5d-a839-4032-b5ab-c48f5b7cbc9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iniciando o processo de download e extração em Mon Oct  7 01:58:17 PM UTC 2024\n",
            "Baixando o arquivo name.basics.tsv.gz...\n",
            "--2024-10-07 13:58:17--  https://datasets.imdbws.com/name.basics.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 273487929 (261M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/name.basics.tsv.gz’\n",
            "\n",
            "name.basics.tsv.gz  100%[===================>] 260.82M   225MB/s    in 1.2s    \n",
            "\n",
            "2024-10-07 13:58:19 (225 MB/s) - ‘./datasets/name.basics.tsv.gz’ saved [273487929/273487929]\n",
            "\n",
            "O download do arquivo name.basics.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.akas.tsv.gz...\n",
            "--2024-10-07 13:58:19--  https://datasets.imdbws.com/title.akas.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 432939409 (413M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.akas.tsv.gz’\n",
            "\n",
            "title.akas.tsv.gz   100%[===================>] 412.88M  96.6MB/s    in 6.6s    \n",
            "\n",
            "2024-10-07 13:58:25 (62.5 MB/s) - ‘./datasets/title.akas.tsv.gz’ saved [432939409/432939409]\n",
            "\n",
            "O download do arquivo title.akas.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.basics.tsv.gz...\n",
            "--2024-10-07 13:58:25--  https://datasets.imdbws.com/title.basics.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 195483304 (186M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.basics.tsv.gz’\n",
            "\n",
            "title.basics.tsv.gz 100%[===================>] 186.43M   114MB/s    in 1.6s    \n",
            "\n",
            "2024-10-07 13:58:27 (114 MB/s) - ‘./datasets/title.basics.tsv.gz’ saved [195483304/195483304]\n",
            "\n",
            "O download do arquivo title.basics.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.crew.tsv.gz...\n",
            "--2024-10-07 13:58:27--  https://datasets.imdbws.com/title.crew.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72691053 (69M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.crew.tsv.gz’\n",
            "\n",
            "title.crew.tsv.gz   100%[===================>]  69.32M   146MB/s    in 0.5s    \n",
            "\n",
            "2024-10-07 13:58:27 (146 MB/s) - ‘./datasets/title.crew.tsv.gz’ saved [72691053/72691053]\n",
            "\n",
            "O download do arquivo title.crew.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.episode.tsv.gz...\n",
            "--2024-10-07 13:58:27--  https://datasets.imdbws.com/title.episode.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 46996631 (45M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.episode.tsv.gz’\n",
            "\n",
            "title.episode.tsv.g 100%[===================>]  44.82M   185MB/s    in 0.2s    \n",
            "\n",
            "2024-10-07 13:58:28 (185 MB/s) - ‘./datasets/title.episode.tsv.gz’ saved [46996631/46996631]\n",
            "\n",
            "O download do arquivo title.episode.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.principals.tsv.gz...\n",
            "--2024-10-07 13:58:28--  https://datasets.imdbws.com/title.principals.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 683887658 (652M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.principals.tsv.gz’\n",
            "\n",
            "title.principals.ts 100%[===================>] 652.21M   229MB/s    in 2.9s    \n",
            "\n",
            "2024-10-07 13:58:31 (229 MB/s) - ‘./datasets/title.principals.tsv.gz’ saved [683887658/683887658]\n",
            "\n",
            "O download do arquivo title.principals.tsv.gz foi realizado com sucesso.\n",
            "Baixando o arquivo title.ratings.tsv.gz...\n",
            "--2024-10-07 13:58:31--  https://datasets.imdbws.com/title.ratings.tsv.gz\n",
            "Resolving datasets.imdbws.com (datasets.imdbws.com)... 3.167.212.55, 3.167.212.123, 3.167.212.68, ...\n",
            "Connecting to datasets.imdbws.com (datasets.imdbws.com)|3.167.212.55|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7456060 (7.1M) [binary/octet-stream]\n",
            "Saving to: ‘./datasets/title.ratings.tsv.gz’\n",
            "\n",
            "title.ratings.tsv.g 100%[===================>]   7.11M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2024-10-07 13:58:31 (83.7 MB/s) - ‘./datasets/title.ratings.tsv.gz’ saved [7456060/7456060]\n",
            "\n",
            "O download do arquivo title.ratings.tsv.gz foi realizado com sucesso.\n",
            "Extraindo o arquivo name.basics.tsv.gz...\n",
            "Extração do arquivo name.basics.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.akas.tsv.gz...\n",
            "Extração do arquivo title.akas.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.basics.tsv.gz...\n",
            "Extração do arquivo title.basics.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.crew.tsv.gz...\n",
            "Extração do arquivo title.crew.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.episode.tsv.gz...\n",
            "Extração do arquivo title.episode.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.principals.tsv.gz...\n",
            "Extração do arquivo title.principals.tsv.gz realizada com sucesso.\n",
            "Extraindo o arquivo title.ratings.tsv.gz...\n",
            "Extração do arquivo title.ratings.tsv.gz realizada com sucesso.\n",
            "Processo finalizado em Mon Oct  7 02:00:14 PM UTC 2024\n"
          ]
        }
      ],
      "source": [
        "# Executa o script responsável pelo download e a extração dos dados utilizados\n",
        "!bash download_and_extract.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBJUBof6sTl1"
      },
      "source": [
        "## Configuração e inicialização do ambiente PySpark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7VzGiEX_pjbp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfa36e97-6ab4-4fd1-aa7e-2b9b23b3c22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# Instalando o pacote do PySpark no ambiente\n",
        "!pip install -q pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wVr3yRuawQtK"
      },
      "outputs": [],
      "source": [
        "# Importando e inicializando o PySpark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
        "from pyspark.sql.functions import split, col\n",
        "\n",
        "spark = SparkSession \\\n",
        "        .builder \\\n",
        "        .appName(\"IMDb\") \\\n",
        "        .master(\"local[*]\") \\\n",
        "        .getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nc2sqx_axT9x"
      },
      "source": [
        "### Criação dos DataFrames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28Mr4niixXD9"
      },
      "source": [
        "Vamos criar os DataFrames para cada um dos arquivos de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZitNutNy2EUk"
      },
      "source": [
        "#### Person"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-gAnV-Sxdge",
        "outputId": "daf53ebf-8b10-4a4c-f79e-918a25747312"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------------+---------+---------+--------------------------------------+--------------------------------------------+\n",
            "|nconst   |primaryName    |birthYear|deathYear|primaryProfession                     |knownForTitles                              |\n",
            "+---------+---------------+---------+---------+--------------------------------------+--------------------------------------------+\n",
            "|nm0000001|Fred Astaire   |1899     |1987     |[actor, miscellaneous, producer]      |[tt0072308, tt0050419, tt0053137, tt0027125]|\n",
            "|nm0000002|Lauren Bacall  |1924     |2014     |[actress, soundtrack, archive_footage]|[tt0037382, tt0075213, tt0117057, tt0038355]|\n",
            "|nm0000003|Brigitte Bardot|1934     |NULL     |[actress, music_department, producer] |[tt0057345, tt0049189, tt0056404, tt0054452]|\n",
            "|nm0000004|John Belushi   |1949     |1982     |[actor, writer, music_department]     |[tt0072562, tt0077975, tt0080455, tt0078723]|\n",
            "|nm0000005|Ingmar Bergman |1918     |2007     |[writer, director, actor]             |[tt0050986, tt0083922, tt0050976, tt0069467]|\n",
            "+---------+---------------+---------+---------+--------------------------------------+--------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "person_schema = StructType([\n",
        "    StructField(\"nconst\", StringType(), True),\n",
        "    StructField(\"primaryName\", StringType(), True),\n",
        "    StructField(\"birthYear\", IntegerType(), True),\n",
        "    StructField(\"deathYear\", IntegerType(), True),\n",
        "    StructField(\"primaryProfession\", StringType(), True),\n",
        "    StructField(\"knownForTitles\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_person = spark.read.csv(\n",
        "    './datasets/name.basics.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=person_schema,\n",
        "    multiLine=False\n",
        ")\n",
        "\n",
        "df_person = df_person.withColumn(\"primaryProfession\", split(df_person[\"primaryProfession\"], \",\"))\n",
        "df_names = df_person.withColumn(\"knownForTitles\", split(df_person[\"knownForTitles\"], \",\"))\n",
        "\n",
        "df_names.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdcPvYLJ2KdU"
      },
      "source": [
        "#### Title translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1kUN_sx21XI3",
        "outputId": "764b5b25-4263-4908-80a0-d5ac7c7d2bdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------------+------+--------+-------------+---------------+---------------+\n",
            "|titleId  |ordering|title                    |region|language|types        |attributes     |isOriginalTitle|\n",
            "+---------+--------+-------------------------+------+--------+-------------+---------------+---------------+\n",
            "|tt0000001|1       |Carmencita               |NULL  |NULL    |[original]   |NULL           |1              |\n",
            "|tt0000001|2       |Carmencita               |DE    |NULL    |NULL         |[literal title]|0              |\n",
            "|tt0000001|3       |Carmencita               |US    |NULL    |[imdbDisplay]|NULL           |0              |\n",
            "|tt0000001|4       |Carmencita - spanyol tánc|HU    |NULL    |[imdbDisplay]|NULL           |0              |\n",
            "|tt0000001|5       |Καρμενσίτα               |GR    |NULL    |[imdbDisplay]|NULL           |0              |\n",
            "+---------+--------+-------------------------+------+--------+-------------+---------------+---------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# title.akas.tsv\n",
        "title_translation_schema = StructType([\n",
        "    StructField(\"titleId\", StringType(), True),\n",
        "    StructField(\"ordering\", IntegerType(), True),\n",
        "    StructField(\"title\", StringType(), True),\n",
        "    StructField(\"region\", StringType(), True),\n",
        "    StructField(\"language\", StringType(), True),\n",
        "    StructField(\"types\", StringType(), True),\n",
        "    StructField(\"attributes\", StringType(), True),\n",
        "    StructField(\"isOriginalTitle\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_title_translation = spark.read.csv(\n",
        "    './datasets/title.akas.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=title_translation_schema,\n",
        "    multiLine=False,\n",
        "    nullValue=r\"\\N\"\n",
        ")\n",
        "\n",
        "df_title_translation = df_title_translation.withColumn(\"types\", split(df_title_translation[\"types\"], \",\"))\n",
        "df_title_translation = df_title_translation.withColumn(\"attributes\", split(df_title_translation[\"attributes\"], \",\"))\n",
        "\n",
        "df_title_translation.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlIDkdTr2NmW"
      },
      "source": [
        "#### Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrQQsT5U0F9f",
        "outputId": "20e567b1-8699-454f-d92d-3bfc40c96ea5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+----------------------------+\n",
            "|tconst   |titleType|primaryTitle          |originalTitle         |isAdult|startYear|endYear|runtimeMinutes|genres                      |\n",
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+----------------------------+\n",
            "|tt0000001|short    |Carmencita            |Carmencita            |0      |1894     |NULL   |1             |[Documentary, Short]        |\n",
            "|tt0000002|short    |Le clown et ses chiens|Le clown et ses chiens|0      |1892     |NULL   |5             |[Animation, Short]          |\n",
            "|tt0000003|short    |Pauvre Pierrot        |Pauvre Pierrot        |0      |1892     |NULL   |5             |[Animation, Comedy, Romance]|\n",
            "|tt0000004|short    |Un bon bock           |Un bon bock           |0      |1892     |NULL   |12            |[Animation, Short]          |\n",
            "|tt0000005|short    |Blacksmith Scene      |Blacksmith Scene      |0      |1893     |NULL   |1             |[Comedy, Short]             |\n",
            "+---------+---------+----------------------+----------------------+-------+---------+-------+--------------+----------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "title_schema = StructType([\n",
        "    StructField(\"tconst\", StringType(), True),\n",
        "    StructField(\"titleType\", StringType(), True),\n",
        "    StructField(\"primaryTitle\", StringType(), True),\n",
        "    StructField(\"originalTitle\", StringType(), True),\n",
        "    StructField(\"isAdult\", IntegerType(), True),\n",
        "    StructField(\"startYear\", IntegerType(), True),\n",
        "    StructField(\"endYear\", IntegerType(), True),\n",
        "    StructField(\"runtimeMinutes\", IntegerType(), True),\n",
        "    StructField(\"genres\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_title = spark.read.csv(\n",
        "    './datasets/title.basics.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=title_schema,\n",
        "    multiLine=False\n",
        ")\n",
        "\n",
        "df_title = df_title.withColumn(\"genres\", split(df_title[\"genres\"], \",\"))\n",
        "\n",
        "df_title.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWYlSnEh2Xn-"
      },
      "source": [
        "#### Crew"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWl2K1xi2WZk",
        "outputId": "becdef08-2d4a-45fe-fd7e-a9a004d38a32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------+-------+\n",
            "|tconst   |directors  |writers|\n",
            "+---------+-----------+-------+\n",
            "|tt0000001|[nm0005690]|NULL   |\n",
            "|tt0000002|[nm0721526]|NULL   |\n",
            "|tt0000003|[nm0721526]|NULL   |\n",
            "|tt0000004|[nm0721526]|NULL   |\n",
            "|tt0000005|[nm0005690]|NULL   |\n",
            "+---------+-----------+-------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "crew_schema = StructType([\n",
        "    StructField(\"tconst\", StringType(), True),\n",
        "    StructField(\"directors\", StringType(), True),\n",
        "    StructField(\"writers\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_crew = spark.read.csv(\n",
        "    './datasets/title.crew.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=crew_schema,\n",
        "    multiLine=False,\n",
        "    nullValue=r\"\\N\"\n",
        ")\n",
        "\n",
        "df_crew = df_crew.withColumn(\"directors\", split(df_crew[\"directors\"], \",\"))\n",
        "df_crew = df_crew.withColumn(\"writers\", split(df_crew[\"writers\"], \",\"))\n",
        "\n",
        "df_crew.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MctV1EvY28la"
      },
      "source": [
        "#### Episode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6ZO58Y229zJ",
        "outputId": "459798d4-941f-4cbe-e0ba-dd3c9da5f160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------------+-------------+\n",
            "|tconst   |parentTconst|seasonNumber|episodeNumber|\n",
            "+---------+------------+------------+-------------+\n",
            "|tt0031458|tt32857063  |NULL        |NULL         |\n",
            "|tt0041951|tt0041038   |1           |9            |\n",
            "|tt0042816|tt0989125   |1           |17           |\n",
            "|tt0042889|tt0989125   |NULL        |NULL         |\n",
            "|tt0043426|tt0040051   |3           |42           |\n",
            "+---------+------------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "episode_schema = StructType([\n",
        "    StructField(\"tconst\", StringType(), True),\n",
        "    StructField(\"parentTconst\", StringType(), True),\n",
        "    StructField(\"seasonNumber\", IntegerType(), True),\n",
        "    StructField(\"episodeNumber\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_episode = spark.read.csv(\n",
        "    './datasets/title.episode.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=episode_schema,\n",
        "    multiLine=False,\n",
        ")\n",
        "\n",
        "df_episode.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81A5TRBk3bck"
      },
      "source": [
        "#### Principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUEMVX1b3c9j",
        "outputId": "1388fccf-3cd7-4929-8c9f-cd62b714905c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "|tconst   |ordering|nconst   |category       |job                    |characters|\n",
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "|tt0000001|1       |nm1588970|self           |NULL                   |[\"Self\"]  |\n",
            "|tt0000001|2       |nm0005690|director       |NULL                   |NULL      |\n",
            "|tt0000001|3       |nm0005690|producer       |producer               |NULL      |\n",
            "|tt0000001|4       |nm0374658|cinematographer|director of photography|NULL      |\n",
            "|tt0000002|1       |nm0721526|director       |NULL                   |NULL      |\n",
            "+---------+--------+---------+---------------+-----------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "principal_schema = StructType([\n",
        "    StructField(\"tconst\", StringType(), True),\n",
        "    StructField(\"ordering\", IntegerType(), True),\n",
        "    StructField(\"nconst\", StringType(), True),\n",
        "    StructField(\"category\", StringType(), True),\n",
        "    StructField(\"job\", StringType(), True),\n",
        "    StructField(\"characters\", StringType(), True)\n",
        "])\n",
        "\n",
        "df_principal = spark.read.csv(\n",
        "    './datasets/title.principals.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=principal_schema,\n",
        "    multiLine=False,\n",
        "    nullValue=r\"\\N\"\n",
        ")\n",
        "\n",
        "df_principal.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOCFva3132QN"
      },
      "source": [
        "#### Rating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAVM1sF834C2",
        "outputId": "7ec35677-6eb2-4c01-a633-9fb985e85314"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+--------+\n",
            "|tconst   |averageRating|numVotes|\n",
            "+---------+-------------+--------+\n",
            "|tt0000001|5.7          |2089    |\n",
            "|tt0000002|5.6          |283     |\n",
            "|tt0000003|6.5          |2097    |\n",
            "|tt0000004|5.4          |183     |\n",
            "|tt0000005|6.2          |2832    |\n",
            "+---------+-------------+--------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rating_schema = StructType([\n",
        "    StructField(\"tconst\", StringType(), True),\n",
        "    StructField(\"averageRating\", FloatType(), True),\n",
        "    StructField(\"numVotes\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "df_rating = spark.read.csv(\n",
        "    './datasets/title.ratings.tsv',\n",
        "    header=True,\n",
        "    sep=\"\\t\",\n",
        "    schema=rating_schema,\n",
        "    multiLine=False\n",
        ")\n",
        "\n",
        "df_rating.show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfQFWBctwvh4"
      },
      "source": [
        "### Criação da tabela base para as análises posteriores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8fwX_-4w2Er"
      },
      "source": [
        "O recorte base é o conjunto de 250 títulos com maior quantidade de avaliações.<br>\n",
        "Todas as 5 análises posteriores usarão esse conjunto de títulos, e por esse motivo optei por guardar os dados em forma de um DataFrame individual."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "CREATE TABLE top_titles AS\n",
        "    (\n",
        "        SELECT\n",
        "            t.tconst,\n",
        "            t.primaryTitle,\n",
        "            r.averageRating,\n",
        "            r.numVotes,\n",
        "            t.startYear,\n",
        "            t.titleType,\n",
        "            t.runtimeMinutes\n",
        "        FROM rating AS r\n",
        "        INNER JOIN title AS t\n",
        "        USING(tconst)\n",
        "        ORDER BY numVotes DESC\n",
        "        LIMIT 250\n",
        "    );\n",
        "```"
      ],
      "metadata": {
        "id": "kwrUXVjKTn1s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "MeCNy4-DT8FA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL4hqcBy4gxQ",
        "outputId": "606c1f48-e543-4d43-cea8-bcc366361a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------------+-------------+--------+---------+---------+--------------+\n",
            "|tconst   |primaryTitle            |averageRating|numVotes|startYear|titleType|runtimeMinutes|\n",
            "+---------+------------------------+-------------+--------+---------+---------+--------------+\n",
            "|tt0111161|The Shawshank Redemption|9.3          |2947499 |1994     |movie    |142           |\n",
            "|tt0468569|The Dark Knight         |9.0          |2927813 |2008     |movie    |152           |\n",
            "|tt1375666|Inception               |8.8          |2599180 |2010     |movie    |148           |\n",
            "|tt0137523|Fight Club              |8.8          |2379193 |1999     |movie    |139           |\n",
            "|tt0944947|Game of Thrones         |9.2          |2350263 |2011     |tvSeries |60            |\n",
            "|tt0109830|Forrest Gump            |8.8          |2305408 |1994     |movie    |142           |\n",
            "|tt0110912|Pulp Fiction            |8.9          |2263378 |1994     |movie    |154           |\n",
            "|tt0903747|Breaking Bad            |9.5          |2213550 |2008     |tvSeries |45            |\n",
            "|tt0816692|Interstellar            |8.7          |2167892 |2014     |movie    |169           |\n",
            "|tt0133093|The Matrix              |8.7          |2092749 |1999     |movie    |136           |\n",
            "+---------+------------------------+-------------+--------+---------+---------+--------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Executando o join entre df_rating e df_title, trazendo as colunas devidas\n",
        "df_top_titles = df_rating.alias(\"r\").join(\n",
        "    df_title.alias(\"t\"),\n",
        "    on=\"tconst\",\n",
        "    how=\"inner\"\n",
        ").select(\n",
        "    col(\"t.tconst\"),\n",
        "    col(\"t.primaryTitle\"),\n",
        "    col(\"r.averageRating\"),\n",
        "    col(\"r.numVotes\"),\n",
        "    col(\"t.startYear\"),\n",
        "    col(\"t.titleType\"),\n",
        "    col(\"t.runtimeMinutes\")\n",
        ").orderBy(col(\"r.numVotes\").desc())\n",
        "\n",
        "# Limitando aos 250 primeiros registros ordenados\n",
        "df_top_titles = df_top_titles.limit(250)\n",
        "\n",
        "# Mostrando 10 dos registros\n",
        "df_top_titles.show(10, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise 1"
      ],
      "metadata": {
        "id": "TU_5VARlUNsk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Distribuição de quantidade de títulos por década e por tipo."
      ],
      "metadata": {
        "id": "rBBkgTy_UUI2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "SELECT\n",
        "    CAST(FLOOR(startYear / 10) * 10 AS INT) AS decade,\n",
        "    titleType,\n",
        "    COUNT(*) AS count\n",
        "FROM top_titles\n",
        "WHERE startYear IS NOT NULL\n",
        "GROUP BY FLOOR(startYear / 10) * 10, titleType\n",
        "ORDER BY FLOOR(startYear / 10) * 10 DESC, titleType DESC;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cR6D2CO1UXKV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "33lTVMj6UeYK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Transformação da query em PySpark\n",
        "df_decades = df_top_titles.filter(F.col(\"startYear\").isNotNull()) \\\n",
        "    .groupBy(\n",
        "        (F.floor(F.col(\"startYear\") / 10) * 10).cast(\"int\").alias(\"decade\"),\n",
        "        F.col(\"titleType\")\n",
        "    ) \\\n",
        "    .agg(F.count(\"*\").alias(\"count\")) \\\n",
        "    .orderBy(F.col(\"decade\").desc(), F.col(\"titleType\").desc())\n",
        "\n",
        "# Resultado\n",
        "df_decades.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdqJ66KpUKyX",
        "outputId": "92640e0a-4062-41aa-8b92-e4d6684925f7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------------+-----+\n",
            "|decade|titleType   |count|\n",
            "+------+------------+-----+\n",
            "|2020  |movie       |5    |\n",
            "|2010  |tvSeries    |10   |\n",
            "|2010  |tvMiniSeries|1    |\n",
            "|2010  |movie       |91   |\n",
            "|2000  |tvSeries    |5    |\n",
            "|2000  |movie       |73   |\n",
            "|1990  |tvSeries    |1    |\n",
            "|1990  |movie       |38   |\n",
            "|1980  |movie       |12   |\n",
            "|1970  |movie       |10   |\n",
            "|1960  |movie       |3    |\n",
            "|1950  |movie       |1    |\n",
            "+------+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise 2"
      ],
      "metadata": {
        "id": "j0CN3GKAVMAm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Média da quantidade de idiomas para os quais os títulos foram traduzidos."
      ],
      "metadata": {
        "id": "Y11vHT_8VMAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "WITH translation_counts AS (\n",
        "    SELECT\n",
        "        titleId AS tconst,\n",
        "        COUNT(*) AS translation_count\n",
        "    FROM\n",
        "        title_translation\n",
        "    GROUP BY\n",
        "        titleId\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    ROUND(AVG(tc.translation_count)) AS avg_translations\n",
        "FROM\n",
        "    top_titles tt\n",
        "INNER JOIN\n",
        "    translation_counts tc ON tt.tconst = tc.tconst;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "5KMHgsdLVMAn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "hyjg6KmzVMAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Criando o DataFrame com a contagem de traduções\n",
        "df_translation_counts = df_title_translation.groupBy(\"titleId\") \\\n",
        "    .agg(F.count(\"*\").alias(\"translation_count\")) \\\n",
        "    .withColumnRenamed(\"titleId\", \"tconst\")\n",
        "\n",
        "# Realizando o join com df_top_titles\n",
        "df_avg_translations = df_top_titles.alias(\"tt\") \\\n",
        "    .join(df_translation_counts.alias(\"tc\"), on=\"tconst\", how=\"inner\") \\\n",
        "    .agg(F.round(F.avg(\"tc.translation_count\")).alias(\"avg_translations\"))\n",
        "\n",
        "# Resultado\n",
        "df_avg_translations.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccdd515b-5e0d-4e0c-a791-ecee1341051a",
        "id": "IZPTOfm7VMAo"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+\n",
            "|avg_translations|\n",
            "+----------------+\n",
            "|70.0            |\n",
            "+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise 3"
      ],
      "metadata": {
        "id": "eLhN5neIVM4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 10 atores e atrizes com mais participações."
      ],
      "metadata": {
        "id": "OAYpkmGXVM4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "WITH actor_appearances AS (\n",
        "    SELECT\n",
        "        pr.nconst AS actor_id,\n",
        "        p.primaryName AS actor_name,\n",
        "        COUNT(*) AS appearance_count\n",
        "    FROM\n",
        "        principal pr\n",
        "    JOIN\n",
        "        top_titles tt ON pr.tconst = tt.tconst\n",
        "    JOIN\n",
        "        person p ON pr.nconst = p.nconst\n",
        "    WHERE\n",
        "        pr.category in ('actor', 'actress')\n",
        "    GROUP BY\n",
        "        pr.nconst, p.primaryName\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    actor_name,\n",
        "    appearance_count\n",
        "FROM\n",
        "    actor_appearances\n",
        "ORDER BY\n",
        "    appearance_count DESC\n",
        "LIMIT 10;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "pPBCMzxuVM4m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "fkAgAr2wVM4m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrando atores e atrizes em df_principal\n",
        "df_actor_appearances = df_principal.filter(F.col(\"category\").isin(\"actor\", \"actress\")) \\\n",
        "    .join(df_top_titles, on=\"tconst\", how=\"inner\") \\\n",
        "    .join(df_person, on=\"nconst\", how=\"inner\") \\\n",
        "    .groupBy(\"nconst\", \"primaryName\") \\\n",
        "    .agg(F.count(\"*\").alias(\"appearance_count\")) \\\n",
        "    .orderBy(F.col(\"appearance_count\").desc())\n",
        "\n",
        "# Selecionando os 10 principais atores/atrizes por número de aparições\n",
        "df_top_actors = df_actor_appearances.select(\"primaryName\", \"appearance_count\") \\\n",
        "    .limit(10)\n",
        "\n",
        "# Resultado\n",
        "df_top_actors.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe96b2ee-16f4-4138-8007-44fd4dc4213b",
        "id": "1AFKLf7DVM4n"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------+----------------+\n",
            "|primaryName       |appearance_count|\n",
            "+------------------+----------------+\n",
            "|Robert Downey Jr. |17              |\n",
            "|Scarlett Johansson|16              |\n",
            "|Chris Evans       |15              |\n",
            "|Samuel L. Jackson |14              |\n",
            "|Mark Ruffalo      |13              |\n",
            "|Don Cheadle       |10              |\n",
            "|Brad Pitt         |10              |\n",
            "|Natalie Portman   |10              |\n",
            "|Leonardo DiCaprio |9               |\n",
            "|Jeremy Renner     |9               |\n",
            "+------------------+----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise 4"
      ],
      "metadata": {
        "id": "_QFya17oVNjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Top 5 diretores com mais participações e se estão vivos"
      ],
      "metadata": {
        "id": "nE3pxsXsVNje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "WITH director_appearances AS (\n",
        "    SELECT\n",
        "        c.tconst,\n",
        "        director AS nconst\n",
        "    FROM\n",
        "        crew c\n",
        "    LATERAL VIEW explode(c.directors) d AS director\n",
        "    WHERE\n",
        "        c.tconst IN (SELECT tconst FROM top_titles)\n",
        "),\n",
        "director_count AS (\n",
        "    SELECT\n",
        "        da.nconst,\n",
        "        COUNT(*) AS appearance_count\n",
        "    FROM\n",
        "        director_appearances da\n",
        "    GROUP BY\n",
        "        da.nconst\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    dc.nconst,\n",
        "    p.primaryName AS director_name,\n",
        "    dc.appearance_count,\n",
        "    CASE\n",
        "        WHEN p.deathYear IS NOT NULL THEN 'Deceased'\n",
        "        ELSE 'Alive'\n",
        "    END AS status\n",
        "FROM\n",
        "    director_count dc\n",
        "JOIN\n",
        "    person p ON dc.nconst = p.nconst\n",
        "ORDER BY\n",
        "    dc.appearance_count DESC\n",
        "LIMIT 5;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "LcsUWiFAVNje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "u7Rx-WqHVNjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrando os títulos presentes em df_top_titles\n",
        "df_director_appearances = df_crew.filter(F.col(\"tconst\").isin([row[\"tconst\"] for row in df_top_titles.collect()])) \\\n",
        "    .select(\"tconst\", F.explode(\"directors\").alias(\"nconst\"))\n",
        "\n",
        "# Contando as aparições dos diretores\n",
        "df_director_count = df_director_appearances.groupBy(\"nconst\") \\\n",
        "    .agg(F.count(\"*\").alias(\"appearance_count\"))\n",
        "\n",
        "# Fazendo join com df_person para obter o nome e status dos diretores\n",
        "df_director_status = df_director_count.join(df_person, on=\"nconst\", how=\"inner\") \\\n",
        "    .select(\n",
        "        \"nconst\",\n",
        "        \"primaryName\",\n",
        "        \"appearance_count\",\n",
        "        F.when(F.col(\"deathYear\").isNotNull(), \"Deceased\").otherwise(\"Alive\").alias(\"status\")\n",
        "    )\n",
        "\n",
        "# Ordenando pelos diretores com mais aparições e limitando a 5\n",
        "df_top_directors = df_director_status.orderBy(F.col(\"appearance_count\").desc()).limit(5)\n",
        "\n",
        "# Resultado\n",
        "df_top_directors.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3570c096-118d-45cd-95e7-b71b7e008690",
        "id": "Y3gObYvRVNjf"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-----------------+----------------+------+\n",
            "|nconst   |primaryName      |appearance_count|status|\n",
            "+---------+-----------------+----------------+------+\n",
            "|nm0634240|Christopher Nolan|9               |Alive |\n",
            "|nm0000233|Quentin Tarantino|9               |Alive |\n",
            "|nm0000229|Steven Spielberg |7               |Alive |\n",
            "|nm0000631|Ridley Scott     |5               |Alive |\n",
            "|nm0000399|David Fincher    |5               |Alive |\n",
            "+---------+-----------------+----------------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Análise 5"
      ],
      "metadata": {
        "id": "EiL15yagVN_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Séries ordenadas por tempo total de duração em minutos, com total de temporadas, total de episódios e duração nominal por episódio."
      ],
      "metadata": {
        "id": "qiEaXl5YVN_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código SQL referência\n",
        "```sql\n",
        "WITH series_info AS (\n",
        "    SELECT\n",
        "        t.tconst,\n",
        "        t.primaryTitle,\n",
        "        COUNT(DISTINCT e.seasonNumber) AS num_seasons,\n",
        "        COUNT(*) AS num_episodes,\n",
        "        MAX(t.runtimeMinutes) AS episode_duration\n",
        "    FROM\n",
        "        top_titles t\n",
        "    LEFT JOIN\n",
        "        episode e ON t.tconst = e.parentTconst\n",
        "    WHERE\n",
        "        t.titleType = 'tvSeries'\n",
        "    GROUP BY\n",
        "        t.tconst, t.primaryTitle\n",
        ")\n",
        "\n",
        "SELECT\n",
        "    primaryTitle,\n",
        "    num_seasons AS total_seasons,\n",
        "    num_episodes AS total_episodes,\n",
        "    episode_duration,\n",
        "    num_episodes * episode_duration AS total_runtime\n",
        "FROM\n",
        "    series_info\n",
        "ORDER BY\n",
        "    num_episodes * episode_duration DESC;\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "WwloiferVN_V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementação PySpark"
      ],
      "metadata": {
        "id": "HkKB-UuzVN_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Filtrando apenas séries de TV em df_top_titles\n",
        "df_series_info = df_top_titles.filter(F.col(\"titleType\") == \"tvSeries\") \\\n",
        "    .join(df_episode, df_top_titles[\"tconst\"] == df_episode[\"parentTconst\"], how=\"left\") \\\n",
        "    .groupBy(df_top_titles[\"tconst\"], df_top_titles[\"primaryTitle\"]) \\\n",
        "    .agg(\n",
        "        F.countDistinct(\"seasonNumber\").alias(\"num_seasons\"),\n",
        "        F.count(\"*\").alias(\"num_episodes\"),\n",
        "        F.max(df_top_titles[\"runtimeMinutes\"]).alias(\"episode_duration\")\n",
        "    )\n",
        "\n",
        "# Calculando o total de runtime\n",
        "df_series_info = df_series_info.withColumn(\n",
        "    \"total_runtime\", F.col(\"num_episodes\") * F.col(\"episode_duration\")\n",
        ")\n",
        "\n",
        "# Selecionando as colunas necessárias e ordenando pelo total de runtime\n",
        "df_series_info_ordered = df_series_info.select(\n",
        "    \"primaryTitle\",\n",
        "    F.col(\"num_seasons\").alias(\"total_seasons\"),\n",
        "    F.col(\"num_episodes\").alias(\"total_episodes\"),\n",
        "    \"episode_duration\",\n",
        "    \"total_runtime\"\n",
        ").orderBy(F.col(\"total_runtime\").desc())\n",
        "\n",
        "# Resultado\n",
        "df_series_info_ordered.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9227c042-1353-40ec-ec13-c2c6274ad209",
        "id": "77kF24mkVN_V"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------+--------------+----------------+-------------+\n",
            "|primaryTitle         |total_seasons|total_episodes|episode_duration|total_runtime|\n",
            "+---------------------+-------------+--------------+----------------+-------------+\n",
            "|The Walking Dead     |11           |177           |45              |7965         |\n",
            "|The Big Bang Theory  |12           |280           |22              |6160         |\n",
            "|Dexter               |8            |96            |60              |5760         |\n",
            "|Friends              |10           |235           |22              |5170         |\n",
            "|How I Met Your Mother|9            |208           |23              |4784         |\n",
            "|Game of Thrones      |8            |74            |60              |4440         |\n",
            "|The Office           |9            |188           |22              |4136         |\n",
            "|Better Call Saul     |6            |63            |45              |2835         |\n",
            "|Breaking Bad         |5            |62            |45              |2790         |\n",
            "|Stranger Things      |5            |42            |60              |2520         |\n",
            "|The Boys             |5            |40            |60              |2400         |\n",
            "|Peaky Blinders       |6            |36            |60              |2160         |\n",
            "|Black Mirror         |7            |33            |60              |1980         |\n",
            "|True Detective       |5            |31            |60              |1860         |\n",
            "|Rick and Morty       |10           |76            |23              |1748         |\n",
            "|Sherlock             |4            |15            |90              |1350         |\n",
            "+---------------------+-------------+--------------+----------------+-------------+\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZitNutNy2EUk",
        "pdcPvYLJ2KdU",
        "FlIDkdTr2NmW",
        "hWYlSnEh2Xn-",
        "MctV1EvY28la",
        "81A5TRBk3bck",
        "qOCFva3132QN"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}